{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42cdf874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d38414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(object):\n",
    "    \n",
    "    def __init__(self, num_inputs=3, hidden_layers=[3, 3], num_outputs=2):\n",
    "        \n",
    "        \n",
    "        self.num_inputs = num_inputs\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.num_outputs = num_outputs\n",
    "        \n",
    "        layers = [num_inputs] + hidden_layers + [num_outputs]\n",
    "        \n",
    "        weights = []\n",
    "        for i in range(len(layers)-1):\n",
    "            w = np.random.rand(layers[i], layers[i+1])\n",
    "            weights.append(w)\n",
    "        self.weights = weights\n",
    "        \n",
    "        derivatives = []\n",
    "        for i in range(len(layers) - 1):\n",
    "            d = np.zeros((layers[i], layers[i + 1]))\n",
    "            derivatives.append(d)\n",
    "        self.derivatives = derivatives\n",
    "        \n",
    "        activations = []\n",
    "        for i in range(len(layers)):\n",
    "            a = np.zeros(layers[i])\n",
    "            activations.append(a)\n",
    "        self.activations = activations\n",
    "        \n",
    "    def forward_propagate(self, inputs):\n",
    "        \"\"\"Computes forward propagation of the network based on input signals.\n",
    "        Args:\n",
    "            inputs (ndarray): Input signals\n",
    "        Returns:\n",
    "            activations (ndarray): Output values\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "        \n",
    "\n",
    "\n",
    "        # the input layer activation is just the input itself\n",
    "        activations = inputs\n",
    "        self.activations[0] = activations\n",
    "\n",
    "        # iterate through the network layers\n",
    "        for i, w in enumerate(self.weights):\n",
    "            # calculate matrix multiplication between previous activation and weight matrix\n",
    "            net_inputs = np.dot(activations, w)\n",
    "\n",
    "            # apply sigmoid activation function\n",
    "            activations = self._sigmoid(net_inputs)\n",
    "\n",
    "            # save the activations for backpropogation\n",
    "            self.activations[i + 1] = activations\n",
    "\n",
    "        # return output layer activation\n",
    "        return activations\n",
    "    def forward_propagate_test(self, inputs):\n",
    "        \"\"\"Computes forward propagation of the network based on input signals.\n",
    "        Args:\n",
    "            inputs (ndarray): Input signals\n",
    "        Returns:\n",
    "            activations (ndarray): Output values\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "\n",
    "        # the input layer activation is just the input itself\n",
    "        activations = inputs\n",
    "        self.activations[0] = activations\n",
    "\n",
    "        # iterate through the network layers\n",
    "        for i, w in enumerate(self.weights):\n",
    "            # calculate matrix multiplication between previous activation and weight matrix\n",
    "            net_inputs = np.dot(activations, w)\n",
    "\n",
    "            # apply sigmoid activation function\n",
    "            activations = self._sigmoid(net_inputs)\n",
    "\n",
    "            # save the activations for backpropogation\n",
    "            self.activations[i + 1] = activations\n",
    "\n",
    "        # return output layer activation\n",
    "        return activations\n",
    "    \n",
    "    def back_propagate(self, error):\n",
    "        \"\"\"Backpropogates an error signal.\n",
    "        Args:\n",
    "            error (ndarray): The error to backprop.\n",
    "        Returns:\n",
    "            error (ndarray): The final error of the input\n",
    "        \"\"\"\n",
    "\n",
    "        # iterate backwards through the network layers\n",
    "        for i in reversed(range(len(self.derivatives))):\n",
    "\n",
    "            # get activation for previous layer\n",
    "            activations = self.activations[i+1]\n",
    "\n",
    "            # apply sigmoid derivative function\n",
    "            delta = error * self._sigmoid_derivative(activations)\n",
    "\n",
    "            # reshape delta as to have it as a 2d array\n",
    "            delta_re = delta.reshape(delta.shape[0], -1).T\n",
    "\n",
    "            # get activations for current layer\n",
    "            current_activations = self.activations[i]\n",
    "\n",
    "            # reshape activations as to have them as a 2d column matrix\n",
    "            current_activations = current_activations.reshape(current_activations.shape[0],-1)\n",
    "\n",
    "            # save derivative after applying matrix multiplication\n",
    "            self.derivatives[i] = np.dot(current_activations, delta_re)\n",
    "\n",
    "            # backpropogate the next error\n",
    "            error = np.dot(delta, self.weights[i].T)\n",
    "            \n",
    "    def train(self, inputs, targets, epochs, learning_rate):\n",
    "        \"\"\"Trains model running forward prop and backprop\n",
    "        Args:\n",
    "            inputs (ndarray): X\n",
    "            targets (ndarray): Y\n",
    "            epochs (int): Num. epochs we want to train the network for\n",
    "            learning_rate (float): Step to apply to gradient descent\n",
    "        \"\"\"\n",
    "        # now enter the training loop\n",
    "        for i in range(epochs):\n",
    "            sum_errors = 0\n",
    "\n",
    "            # iterate through all the training data\n",
    "            for j, input in enumerate(inputs):\n",
    "                target = targets[j]\n",
    "\n",
    "                # activate the network!\n",
    "                output = self.forward_propagate(input)\n",
    "\n",
    "                error = target - output\n",
    "\n",
    "                self.back_propagate(error)\n",
    "\n",
    "                # now perform gradient descent on the derivatives\n",
    "                # (this will update the weights\n",
    "                self.gradient_descent(learning_rate)\n",
    "\n",
    "                # keep track of the MSE for reporting later\n",
    "                sum_errors += self._mse(target, output)\n",
    "\n",
    "            # Epoch complete, report the training error\n",
    "            print(\"Error: {} at epoch {}\".format(sum_errors / len(items), i+1))\n",
    "\n",
    "        print(\"Training complete!\")\n",
    "        print(\"=====\")\n",
    "    \n",
    "    def _sigmoid(self, x):\n",
    "        \"\"\"Sigmoid activation function\n",
    "        Args:\n",
    "            x (float): Value to be processed\n",
    "        Returns:\n",
    "            y (float): Output\n",
    "        \"\"\"\n",
    "        \n",
    "        y = 1.0 / (1 + np.exp(-x))\n",
    "        return y\n",
    "    \n",
    "    \n",
    "    def gradient_descent(self, learningRate=1):\n",
    "        \"\"\"Learns by descending the gradient\n",
    "        Args:\n",
    "            learningRate (float): How fast to learn.\n",
    "        \"\"\"\n",
    "        # update the weights by stepping down the gradient\n",
    "        for i in range(len(self.weights)):\n",
    "            weights = self.weights[i]\n",
    "            derivatives = self.derivatives[i]\n",
    "            weights += derivatives * learningRate\n",
    "            \n",
    "    def _sigmoid_derivative(self, x):\n",
    "        \"\"\"Sigmoid derivative function\n",
    "        Args:\n",
    "            x (float): Value to be processed\n",
    "        Returns:\n",
    "            y (float): Output\n",
    "        \"\"\"\n",
    "        return x * (1.0 - x)\n",
    "    \n",
    "    def _mse(self, target, output):\n",
    "        \"\"\"Mean Squared Error loss function\n",
    "        Args:\n",
    "            target (ndarray): The ground trut\n",
    "            output (ndarray): The predicted values\n",
    "        Returns:\n",
    "            (float): Output\n",
    "        \"\"\"\n",
    "        return np.average((target - output) ** 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def create_seed(self):\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.seed_weights = None\n",
    "        self.seed_derivatives = None\n",
    "        self.seed_activations = None\n",
    "        \n",
    "        self.seed_weights = self.weights[:-2]\n",
    "        self.seed_derivatives = self.derivatives[:-2]\n",
    "        self.seed_activations = self.activations[:-1]\n",
    "\n",
    "        \n",
    "    \n",
    "    #Prime base network\n",
    "    \n",
    "    def prime_base_network(self, inputs, targets, cycles, learning_rate = 0.5):\n",
    "        \n",
    "        self.train(inputs, targets, cycles, 0.5)\n",
    "        \n",
    "    def remove_temp_classifier(self):\n",
    "\n",
    "        \n",
    "        self.weights.pop()\n",
    "        self.derivatives.pop()\n",
    "        self.activations.pop()\n",
    "    \n",
    "    def add_destination_layer(self):\n",
    "        w = np.random.rand(self.weights[-1].shape[0], self.weights[-1].shape[1])\n",
    "        self.weights.append(w)\n",
    "        \n",
    "        d = np.zeros((self.derivatives[-1].shape[0], self.derivatives[-1].shape[1]))\n",
    "        self.derivatives.append(d)\n",
    "        \n",
    "        a = np.zeros(len(self.activations[-1]))\n",
    "        self.activations.append(a)\n",
    "    \n",
    "    def add_class_layer_final(self, targets, shape):\n",
    "        \n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "        \n",
    "        num_classes = len(np.unique(targets))\n",
    "        w = np.random.rand(shape, num_classes)\n",
    "        self.weights.append(w)\n",
    "    \n",
    "        d = np.zeros((shape, num_classes))\n",
    "        self.derivatives.append(d)\n",
    "        \n",
    "        class_activation = np.zeros(num_classes)\n",
    "        self.activations.append(class_activation)\n",
    "    \n",
    "    \n",
    "    def add_class_layer(self, targets):\n",
    "        \n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "        \n",
    "        num_classes = len(np.unique(targets))\n",
    "        w = np.random.rand(self.weights[-1].shape[0], num_classes)\n",
    "        self.weights.append(w)\n",
    "    \n",
    "        d = np.zeros((self.derivatives[-1].shape[0], num_classes))\n",
    "        self.derivatives.append(d)\n",
    "        \n",
    "        class_activation = np.zeros(num_classes)\n",
    "        self.activations.append(class_activation)\n",
    "    \n",
    "    def create_temp_classifier_seed(self, targets):\n",
    "        \n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "        \n",
    "        num_classes = len(np.unique(targets))\n",
    "        w = np.random.rand(self.seed_weights[-1].shape[0], num_classes)\n",
    "        self.seed_weights.append(w)\n",
    "        \n",
    "        d = np.zeros((self.seed_derivatives[-1].shape[0], num_classes))\n",
    "        self.seed_derivatives.append(d)\n",
    "        \n",
    "        class_activation = np.zeros(num_classes)\n",
    "        self.seed_activations.append(class_activation)\n",
    "    \n",
    "    def forward_propagate_seed(self, inputs):\n",
    "        \"\"\"Computes forward propagation of the network based on input signals.\n",
    "        Args:\n",
    "            inputs (ndarray): Input signals\n",
    "        Returns:\n",
    "            activations (ndarray): Output values\n",
    "        \"\"\"\n",
    "\n",
    "        # the input layer activation is just the input itself\n",
    "        activations = inputs\n",
    "        self.seed_activations[0] = activations\n",
    "\n",
    "        # iterate through the network layers\n",
    "        for i, w in enumerate(self.seed_weights):\n",
    "            # calculate matrix multiplication between previous activation and weight matrix\n",
    "            net_inputs = np.dot(activations, w)\n",
    "\n",
    "            # apply sigmoid activation function\n",
    "            activations = self._sigmoid(net_inputs)\n",
    "\n",
    "            # save the activations for backpropogation\n",
    "            self.seed_activations[i + 1] = activations\n",
    "\n",
    "        # return output layer activation\n",
    "        return activations\n",
    "    \n",
    "    def back_propagate_seed(self, error):\n",
    "        \"\"\"Backpropogates an error signal.\n",
    "        Args:\n",
    "            error (ndarray): The error to backprop.\n",
    "        Returns:\n",
    "            error (ndarray): The final error of the input\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "\n",
    "        # iterate backwards through the network layers\n",
    "        for i in reversed(range(len(self.seed_derivatives))):\n",
    "\n",
    "            # get activation for previous layer\n",
    "            activations = self.seed_activations[i+1]\n",
    "\n",
    "            # apply sigmoid derivative function\n",
    "            delta = error * self._sigmoid_derivative(activations)\n",
    "\n",
    "            # reshape delta as to have it as a 2d array\n",
    "            delta_re = delta.reshape(delta.shape[0], -1).T\n",
    "\n",
    "            # get activations for current layer\n",
    "            current_activations = self.seed_activations[i]\n",
    "\n",
    "            # reshape activations as to have them as a 2d column matrix\n",
    "            current_activations = current_activations.reshape(current_activations.shape[0],-1)\n",
    "\n",
    "            # save derivative after applying matrix multiplication\n",
    "            self.seed_derivatives[i] = np.dot(current_activations, delta_re)\n",
    "\n",
    "            # backpropogate the next error\n",
    "            error = np.dot(delta, self.seed_weights[i].T)\n",
    "    \n",
    "    def train_seed(self, inputs, targets, epochs, learning_rate = 0.5):\n",
    "        \"\"\"Trains model running forward prop and backprop\n",
    "        Args:\n",
    "            inputs (ndarray): X\n",
    "            targets (ndarray): Y\n",
    "            epochs (int): Num. epochs we want to train the network for\n",
    "            learning_rate (float): Step to apply to gradient descent\n",
    "        \"\"\"\n",
    "        # now enter the training loop\n",
    "        for i in range(epochs):\n",
    "            sum_errors = 0\n",
    "\n",
    "            # iterate through all the training data\n",
    "            for j, input in enumerate(inputs):\n",
    "                target = targets[j]\n",
    "\n",
    "                # activate the network!\n",
    "                output = self.forward_propagate_seed(input)\n",
    "\n",
    "                error = target - output\n",
    "\n",
    "                self.back_propagate_seed(error)\n",
    "\n",
    "                # now perform gradient descent on the derivatives\n",
    "                # (this will update the weights\n",
    "                self.gradient_descent(learning_rate)\n",
    "\n",
    "                # keep track of the MSE for reporting later\n",
    "                sum_errors += self._mse(target, output)\n",
    "\n",
    "            # Epoch complete, report the training error\n",
    "            #print(\"Error: {} at epoch {}\".format(sum_errors / len(items), i+1))\n",
    "\n",
    "        print(\"Training complete!\")\n",
    "        print(\"=====\")\n",
    "        \n",
    "    def prime_seed_network(self, inputs, targets, cycles, learning_rate = 0.5):\n",
    "        \n",
    "        self.train_seed(inputs, targets, cycles, 0.5)\n",
    "        \n",
    "    def remove_temp_classifier_seed(self):\n",
    "        self.seed_weights.pop()\n",
    "        self.seed_derivatives.pop()\n",
    "        self.seed_activations.pop()\n",
    "    \n",
    "    def extreme_member_classes(self, inputs, targets):\n",
    "        \n",
    "        #Create a temporary seed matrix\n",
    "        self.create_seed()\n",
    "        #Attatch a temp Classification layer\n",
    "        self.create_temp_classifier_seed(targets)\n",
    "        #Prime Seed \n",
    "        self.prime_seed_network(inputs, targets, cycles = 10)\n",
    "        #remove the temporary classifier\n",
    "        self.remove_temp_classifier_seed()\n",
    "        #for each class in the dataset:\n",
    "        \n",
    "        Classes = np.unique(targets)\n",
    "        sorted_classes_list = []\n",
    "        #Loop through the classes in the dataset\n",
    "        for i in Classes:\n",
    "            count = targets.tolist().count(i)  #The number of class members \n",
    "            sum_perceptron = []\n",
    "            avg_perceptron = []\n",
    "            \n",
    "            #initialize the perceptrons\n",
    "            for j in range(len(self.seed_weights[-1])):\n",
    "                sum_perceptron.append(0)\n",
    "            #for each member in the dataclass forward propogate\n",
    "            filter_indices = np.where(targets == i)\n",
    "            Class_inputs = np.take(inputs, filter_indices, axis = 0)\n",
    "            for inp in Class_inputs[0]: \n",
    "                output_single = self.forward_propagate_seed(inp)\n",
    "                #find the outputs at the last layer\n",
    "                for k in range(len(self.seed_weights[-1])):\n",
    "                    sum_perceptron[k] += output_single[k]\n",
    "            for s in sum_perceptron:\n",
    "                avg_perceptron.append(s/count)\n",
    "            Error_list = []\n",
    "            #Find the avg - individual_output -> Error\n",
    "            for inp in Class_inputs[0]:\n",
    "                err = 0\n",
    "                output_single = self.forward_propagate_seed(inp)\n",
    "                for o in range(len(output_single)):\n",
    "                    err += avg_perceptron[o] - output_single[o]\n",
    "                Error_list.append(err)\n",
    "            sort_indices = np.argsort(Error_list)\n",
    "            #sort the class members according to errors. The first and the last members of the sorted list would be termed as extreme members\n",
    "            Class_sorted = Class_inputs[0][sort_indices]\n",
    "            sorted_classes_list.append(Class_sorted)\n",
    "        return sorted_classes_list\n",
    "    \n",
    "    def return_source_activations(self):\n",
    "        #return activations of the source layer\n",
    "        return self.activations[-2]\n",
    "    \n",
    "    def return_acc(self, inputs, targets):\n",
    "        pred = []\n",
    "        for i in inputs:\n",
    "            output = self.forward_propagate(i)\n",
    "            pred.append(np.argmax(output))\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        acc = accuracy_score(targets, pred)\n",
    "        print(pred)\n",
    "        return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bacbe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Alternate### This works better now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53cc0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANG(inputs, targets):\n",
    "    #initialize the multilayer perceptron to take 2 inputs and generate a binary classifier\n",
    "    mlp = MLP(2, [3, 3], 2)\n",
    "    #Prime the base network for 10 epochs\n",
    "    mlp.prime_base_network(inputs, targets, cycles = 10)\n",
    "    #Strip the network of the partially fitted classifier\n",
    "    mlp.remove_temp_classifier()\n",
    "    #Add an empty destination layer\n",
    "    mlp.add_destination_layer()\n",
    "    #Add an untrained classification layer\n",
    "    mlp.add_class_layer(targets)\n",
    "    accuracy = 0\n",
    "    items = inputs\n",
    "    test_targets = targets\n",
    "    percep = 0\n",
    "    \n",
    "    #Place a stopping value on accuracy\n",
    "    while accuracy<0.9:\n",
    "        #Returns a list of n lists, where n is the number of classes in the dataset. Each of the inner lists consists of all the members of a particular class, arranged in order of the distance of their individual output from the average output\n",
    "        sorted_classes = mlp.extreme_member_classes(inputs, targets)\n",
    "        mlp.remove_temp_classifier()\n",
    "        \n",
    "        for i in sorted_classes:\n",
    "            #Loop through each class and identify the extreme members\n",
    "            extremes = []\n",
    "            extremes.append(i[0])\n",
    "            extremes.append(i[-1])\n",
    "            #Loop through the extreme members\n",
    "            for ext in extremes:\n",
    "                #Propogate each extreme member through the network\n",
    "                op = mlp.forward_propagate_test(ext)\n",
    "                #Pull out the outputs at the source layer\n",
    "                fp_output = mlp.return_source_activations()\n",
    "                sum_op = 0\n",
    "                #Find the sum of the outputs\n",
    "                for s in fp_output:\n",
    "                    sum_op += s\n",
    "                #Find the average of the outputs\n",
    "                average = np.average(fp_output)\n",
    "                sum_avg = 0\n",
    "                for s in fp_output:\n",
    "                    sum_avg += (average - s) * (average - s)\n",
    "                sd = np.std(fp_output)\n",
    "                x = 1 # X is the number of standard deviation units at which to set the threshold\n",
    "                try:\n",
    "                    #Try and see if there already exists a neuron to which to map the extreme member's output\n",
    "                    mlp.activations[-1][percep] = 0\n",
    "                except:\n",
    "                    #If no neuron is present, create a new one by initialzing new weights, derivatives and activations\n",
    "                    temp_weights = []\n",
    "                    for w in range(len(mlp.weights[-1])):\n",
    "                        print(mlp.weights[-1][w])\n",
    "                        temp_weights.append(np.append(mlp.weights[-1][w],np.random.rand()))\n",
    "                    mlp.weights[-1] = np.array(temp_weights)\n",
    "                    temp_derivatives = []\n",
    "                    for d in range(len(mlp.derivatives[-1])):\n",
    "                        temp_derivatives.append(np.append(mlp.derivatives[-1][d],0))\n",
    "                    mlp.derivatives[-1] = np.array(temp_derivatives)\n",
    "                    mlp.activations[-1] = np.append(mlp.activations[-1], 0)\n",
    "                    \n",
    "                percep = percep + 1\n",
    "                \n",
    "                #Check if each of the source layer outputs meet the threshold\n",
    "                for conn in range(len(fp_output)):\n",
    "                    #If they do, they are termed as critical connections and the weights are preserved\n",
    "                    if fp_output[conn] >= x*sd or fp_output[conn]<= -x*sd:\n",
    "                        print(\"This is a critical connection\")\n",
    "                    else:\n",
    "                        #If not, the weights are set to 0 and the connection is weakened \n",
    "                        print(\"This is not a critical connection\")\n",
    "        \n",
    "                        length = len(mlp.weights[-1])\n",
    "                        for weights in mlp.weights[-1]:\n",
    "                            weights[conn] = 0\n",
    "        #Bring back the classification layer and train the model on all the data\n",
    "        mlp.add_class_layer_final(targets, mlp.weights[-1].shape[1])\n",
    "        mlp.train(inputs, targets, 50, 0.5)\n",
    "        #Check if the accuracy meets the threshold\n",
    "        accuracy = mlp.return_acc(items, test_targets)\n",
    "        extreme_members = []\n",
    "        #Remove the extreme class members from the dataset and repeat the process until the target metrics are met\n",
    "        for i in sorted_classes:\n",
    "            extreme_members.append(i[0])\n",
    "            extreme_members.append(i[-1])\n",
    "        for i in extreme_members:\n",
    "            ind = np.where(inputs == i)\n",
    "            inputs = np.delete(inputs, ind[0][0], 0)\n",
    "            targets = np.delete(targets, ind[0][0])\n",
    "        print(accuracy)\n",
    "    print(mlp.weights)\n",
    "    return mlp\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa33e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "393c2557",
   "metadata": {},
   "outputs": [],
   "source": [
    "items, targets = make_classification(n_features=2, n_redundant=0, n_informative=1, n_clusters_per_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5ea7463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.2634815972560526 at epoch 1\n",
      "Error: 0.2499587393403544 at epoch 2\n",
      "Error: 0.24169899653805857 at epoch 3\n",
      "Error: 0.21188170994403305 at epoch 4\n",
      "Error: 0.14156469884679498 at epoch 5\n",
      "Error: 0.08527363240662984 at epoch 6\n",
      "Error: 0.06284793693746743 at epoch 7\n",
      "Error: 0.05367582420920198 at epoch 8\n",
      "Error: 0.04917555712853198 at epoch 9\n",
      "Error: 0.04665942709844988 at epoch 10\n",
      "Training complete!\n",
      "=====\n",
      "Training complete!\n",
      "=====\n",
      "This is a critical connection\n",
      "This is a critical connection\n",
      "This is a critical connection\n",
      "This is a critical connection\n",
      "This is not a critical connection\n",
      "This is a critical connection\n",
      "This is a critical connection\n",
      "This is a critical connection\n",
      "This is a critical connection\n",
      "[0.74536261 0.         0.0189667 ]\n",
      "[0.48648922 0.         0.45173339]\n",
      "[0.34629423 0.         0.23829522]\n",
      "This is a critical connection\n",
      "This is not a critical connection\n",
      "This is a critical connection\n",
      "Error: 0.25157472868829944 at epoch 1\n",
      "Error: 0.17489206791666045 at epoch 2\n",
      "Error: 0.09144666567782504 at epoch 3\n",
      "Error: 0.06102714851947345 at epoch 4\n",
      "Error: 0.051214041207162844 at epoch 5\n",
      "Error: 0.046846023201920106 at epoch 6\n",
      "Error: 0.044530176357100985 at epoch 7\n",
      "Error: 0.04318495550607814 at epoch 8\n",
      "Error: 0.04233684055905009 at epoch 9\n",
      "Error: 0.04176005744557843 at epoch 10\n",
      "Error: 0.041342500388394196 at epoch 11\n",
      "Error: 0.04102539001408613 at epoch 12\n",
      "Error: 0.04077587562333052 at epoch 13\n",
      "Error: 0.040574298947228346 at epoch 14\n",
      "Error: 0.040408110761022936 at epoch 15\n",
      "Error: 0.04026885086745113 at epoch 16\n",
      "Error: 0.04015056465631099 at epoch 17\n",
      "Error: 0.040048918734096495 at epoch 18\n",
      "Error: 0.0399606758170842 at epoch 19\n",
      "Error: 0.039883366001478106 at epoch 20\n",
      "Error: 0.03981507186146423 at epoch 21\n",
      "Error: 0.039754282949772235 at epoch 22\n",
      "Error: 0.039699794420883554 at epoch 23\n",
      "Error: 0.03965063468641284 at epoch 24\n",
      "Error: 0.039606012728142986 at epoch 25\n",
      "Error: 0.03956527904820237 at epoch 26\n",
      "Error: 0.03952789627966542 at epoch 27\n",
      "Error: 0.03949341676659579 at epoch 28\n",
      "Error: 0.03946146525379558 at epoch 29\n",
      "Error: 0.03943172537686597 at epoch 30\n",
      "Error: 0.03940392901527108 at epoch 31\n",
      "Error: 0.03937784782741041 at epoch 32\n",
      "Error: 0.03935328646625382 at epoch 33\n",
      "Error: 0.03933007710179137 at epoch 34\n",
      "Error: 0.03930807496862432 at epoch 35\n",
      "Error: 0.03928715472425235 at epoch 36\n",
      "Error: 0.039267207453266416 at epoch 37\n",
      "Error: 0.039248138189717154 at epoch 38\n",
      "Error: 0.039229863857862035 at epoch 39\n",
      "Error: 0.03921231155273859 at epoch 40\n",
      "Error: 0.03919541709830279 at epoch 41\n",
      "Error: 0.03917912383346375 at epoch 42\n",
      "Error: 0.03916338158614986 at epoch 43\n",
      "Error: 0.03914814580322779 at epoch 44\n",
      "Error: 0.03913337681015821 at epoch 45\n",
      "Error: 0.0391190391790855 at epoch 46\n",
      "Error: 0.03910510118790239 at epoch 47\n",
      "Error: 0.0390915343559134 at epoch 48\n",
      "Error: 0.03907831304420997 at epoch 49\n",
      "Error: 0.03906541411088829 at epoch 50\n",
      "Training complete!\n",
      "=====\n",
      "[1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
      "0.06\n",
      "Training complete!\n",
      "=====\n",
      "[ 1.32016063 -1.13761329  0.31007757 -1.22979357]\n",
      "[ 2.17880074 -2.01131173  0.91463864 -2.0707747 ]\n",
      "[-2.89332631  2.37906101 -0.28194234  2.83405753]\n",
      "This is a critical connection\n",
      "This is a critical connection\n",
      "This is not a critical connection\n",
      "[ 1.32016063 -1.13761329  0.         -1.22979357  0.81607189]\n",
      "[ 2.17880074 -2.01131173  0.         -2.0707747   0.46678861]\n",
      "[-2.89332631  2.37906101  0.          2.83405753  0.69829163]\n",
      "This is a critical connection\n",
      "This is a critical connection\n",
      "This is a critical connection\n",
      "[ 1.32016063 -1.13761329  0.         -1.22979357  0.81607189  0.30041272]\n",
      "[ 2.17880074 -2.01131173  0.         -2.0707747   0.46678861  0.04265247]\n",
      "[-2.89332631  2.37906101  0.          2.83405753  0.69829163  0.35877936]\n",
      "This is a critical connection\n",
      "This is a critical connection\n",
      "This is not a critical connection\n",
      "[ 1.32016063 -1.13761329  0.         -1.22979357  0.81607189  0.30041272\n",
      "  0.35029952]\n",
      "[ 2.17880074 -2.01131173  0.         -2.0707747   0.46678861  0.04265247\n",
      "  0.06326978]\n",
      "[-2.89332631  2.37906101  0.          2.83405753  0.69829163  0.35877936\n",
      "  0.89695906]\n",
      "This is not a critical connection\n",
      "This is not a critical connection\n",
      "This is a critical connection\n",
      "Error: 0.20163637288282174 at epoch 1\n",
      "Error: 0.07722819203461044 at epoch 2\n",
      "Error: 0.04614312986857517 at epoch 3\n",
      "Error: 0.03600618724734128 at epoch 4\n",
      "Error: 0.031716435299952946 at epoch 5\n",
      "Error: 0.02951785272651927 at epoch 6\n",
      "Error: 0.028222876158606632 at epoch 7\n",
      "Error: 0.027376800355497787 at epoch 8\n",
      "Error: 0.02678215950262801 at epoch 9\n",
      "Error: 0.0263425313354833 at epoch 10\n",
      "Error: 0.026005290428204552 at epoch 11\n",
      "Error: 0.025739047919225586 at epoch 12\n",
      "Error: 0.025523862008267843 at epoch 13\n",
      "Error: 0.02534647516706625 at epoch 14\n",
      "Error: 0.025197757200216747 at epoch 15\n",
      "Error: 0.02507123374526722 at epoch 16\n",
      "Error: 0.024962197462081726 at epoch 17\n",
      "Error: 0.024867150832016707 at epoch 18\n",
      "Error: 0.024783445692122746 at epoch 19\n",
      "Error: 0.02470904347864882 at epoch 20\n",
      "Error: 0.02464235175627032 at epoch 21\n",
      "Error: 0.024582110266555747 at epoch 22\n",
      "Error: 0.02452730991141028 at epoch 23\n",
      "Error: 0.02447713412761977 at epoch 24\n",
      "Error: 0.02443091578811922 at epoch 25\n",
      "Error: 0.0243881050633317 at epoch 26\n",
      "Error: 0.02434824514425184 at epoch 27\n",
      "Error: 0.024310953687393597 at epoch 28\n",
      "Error: 0.02427590847960643 at epoch 29\n",
      "Error: 0.02424283625288805 at epoch 30\n",
      "Error: 0.024211503876823737 at epoch 31\n",
      "Error: 0.024181711364148328 at epoch 32\n",
      "Error: 0.024153286272144647 at epoch 33\n",
      "Error: 0.02412607918816168 at epoch 34\n",
      "Error: 0.024099960064117812 at epoch 35\n",
      "Error: 0.0240748152210026 at epoch 36\n",
      "Error: 0.024050544885968493 at epoch 37\n",
      "Error: 0.024027061155679746 at epoch 38\n",
      "Error: 0.024004286303014502 at epoch 39\n",
      "Error: 0.02398215136202356 at epoch 40\n",
      "Error: 0.023960594939690636 at epoch 41\n",
      "Error: 0.023939562213562703 at epoch 42\n",
      "Error: 0.023919004082494942 at epoch 43\n",
      "Error: 0.02389887644414863 at epoch 44\n",
      "Error: 0.023879139577909866 at epoch 45\n",
      "Error: 0.02385975761587855 at epoch 46\n",
      "Error: 0.023840698087745277 at epoch 47\n",
      "Error: 0.023821931527909568 at epoch 48\n",
      "Error: 0.02380343113523171 at epoch 49\n",
      "Error: 0.023785172477458816 at epoch 50\n",
      "Training complete!\n",
      "=====\n",
      "[1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0]\n",
      "0.88\n",
      "Training complete!\n",
      "=====\n",
      "[ 1.09550189 -0.94560194 -0.8213231  -1.70473963  1.2856126  -0.69058755\n",
      " -0.17877446  1.36471981]\n",
      "[ 1.40319307 -1.14689354 -0.9765451  -2.84228129  1.12881286 -1.12486474\n",
      " -0.52433221  1.44037485]\n",
      "[-1.56347905  0.95980226  0.71220007  4.13784859 -0.43451919  1.14057506\n",
      "  1.10070048 -0.44191035]\n",
      "This is a critical connection\n",
      "This is a critical connection\n",
      "This is not a critical connection\n",
      "[ 1.09550189 -0.94560194  0.         -1.70473963  1.2856126  -0.69058755\n",
      " -0.17877446  1.36471981  0.24950029]\n",
      "[ 1.40319307 -1.14689354  0.         -2.84228129  1.12881286 -1.12486474\n",
      " -0.52433221  1.44037485  0.38830041]\n",
      "[-1.56347905  0.95980226  0.          4.13784859 -0.43451919  1.14057506\n",
      "  1.10070048 -0.44191035  0.35685433]\n",
      "This is a critical connection\n",
      "This is a critical connection\n",
      "This is a critical connection\n",
      "[ 1.09550189 -0.94560194  0.         -1.70473963  1.2856126  -0.69058755\n",
      " -0.17877446  1.36471981  0.24950029  0.01780973]\n",
      "[ 1.40319307 -1.14689354  0.         -2.84228129  1.12881286 -1.12486474\n",
      " -0.52433221  1.44037485  0.38830041  0.83334368]\n",
      "[-1.56347905  0.95980226  0.          4.13784859 -0.43451919  1.14057506\n",
      "  1.10070048 -0.44191035  0.35685433  0.65110441]\n",
      "This is a critical connection\n",
      "This is a critical connection\n",
      "This is not a critical connection\n",
      "[ 1.09550189 -0.94560194  0.         -1.70473963  1.2856126  -0.69058755\n",
      " -0.17877446  1.36471981  0.24950029  0.01780973  0.01672901]\n",
      "[ 1.40319307 -1.14689354  0.         -2.84228129  1.12881286 -1.12486474\n",
      " -0.52433221  1.44037485  0.38830041  0.83334368  0.63114185]\n",
      "[-1.56347905  0.95980226  0.          4.13784859 -0.43451919  1.14057506\n",
      "  1.10070048 -0.44191035  0.35685433  0.65110441  0.85288546]\n",
      "This is not a critical connection\n",
      "This is not a critical connection\n",
      "This is a critical connection\n",
      "Error: 0.22881362837690422 at epoch 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.037275528251753426 at epoch 2\n",
      "Error: 0.023726857708996105 at epoch 3\n",
      "Error: 0.019387150440076495 at epoch 4\n",
      "Error: 0.017269771805716504 at epoch 5\n",
      "Error: 0.01599456559772611 at epoch 6\n",
      "Error: 0.015113803324373693 at epoch 7\n",
      "Error: 0.014450660162200289 at epoch 8\n",
      "Error: 0.013928472913497737 at epoch 9\n",
      "Error: 0.013508971413270792 at epoch 10\n",
      "Error: 0.013168568346976 at epoch 11\n",
      "Error: 0.012889927136115045 at epoch 12\n",
      "Error: 0.012659255857214067 at epoch 13\n",
      "Error: 0.012465497364313486 at epoch 14\n",
      "Error: 0.012300002535151342 at epoch 15\n",
      "Error: 0.012156222528578812 at epoch 16\n",
      "Error: 0.012029332972725073 at epoch 17\n",
      "Error: 0.011915836283833105 at epoch 18\n",
      "Error: 0.01181320362725188 at epoch 19\n",
      "Error: 0.011719589315921661 at epoch 20\n",
      "Error: 0.01163362102849079 at epoch 21\n",
      "Error: 0.011554253529402642 at epoch 22\n",
      "Error: 0.0114806695838008 at epoch 23\n",
      "Error: 0.011412213638385208 at epoch 24\n",
      "Error: 0.01134834741004106 at epoch 25\n",
      "Error: 0.011288619859704483 at epoch 26\n",
      "Error: 0.011232646565454191 at epoch 27\n",
      "Error: 0.011180095262656266 at epoch 28\n",
      "Error: 0.011130675473436562 at epoch 29\n",
      "Error: 0.01108413088887142 at epoch 30\n",
      "Error: 0.011040233638017831 at epoch 31\n",
      "Error: 0.010998779876462255 at epoch 32\n",
      "Error: 0.010959586317317164 at epoch 33\n",
      "Error: 0.010922487449909939 at epoch 34\n",
      "Error: 0.010887333270977108 at epoch 35\n",
      "Error: 0.010853987405652254 at epoch 36\n",
      "Error: 0.010822325530664945 at epoch 37\n",
      "Error: 0.010792234036059842 at epoch 38\n",
      "Error: 0.010763608878258552 at epoch 39\n",
      "Error: 0.010736354588891703 at epoch 40\n",
      "Error: 0.010710383412116947 at epoch 41\n",
      "Error: 0.0106856145491573 at epoch 42\n",
      "Error: 0.010661973493233385 at epoch 43\n",
      "Error: 0.01063939144139001 at epoch 44\n",
      "Error: 0.01061780477224813 at epoch 45\n",
      "Error: 0.010597154580665675 at epoch 46\n",
      "Error: 0.010577386261819179 at epoch 47\n",
      "Error: 0.01055844913842783 at epoch 48\n",
      "Error: 0.010540296125814167 at epoch 49\n",
      "Error: 0.010522883430281939 at epoch 50\n",
      "Training complete!\n",
      "=====\n",
      "[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "0.51\n",
      "Training complete!\n",
      "=====\n",
      "[ 0.22591313 -0.21430375  0.33657274 -1.84553928  1.46962915 -1.17070759\n",
      " -0.87953255  1.42336487  0.37089734 -0.32625016  0.0485132   0.59605682]\n",
      "[ 0.2620631  -0.23374238  0.38735267 -3.0848038   1.42453203 -1.73977595\n",
      " -1.33899673  1.58777895  0.53631739  0.45651289  0.67431732  0.31404177]\n",
      "[-0.28149464  0.07340172 -0.37745453  4.71754462 -1.58677255  2.21832487\n",
      "  1.83588149 -1.41898173  0.11215874  0.78418917  0.72647809  0.04382734]\n",
      "This is a critical connection\n",
      "This is a critical connection\n",
      "This is not a critical connection\n",
      "[ 0.22591313 -0.21430375  0.         -1.84553928  1.46962915 -1.17070759\n",
      " -0.87953255  1.42336487  0.37089734 -0.32625016  0.0485132   0.59605682\n",
      "  0.55706958]\n",
      "[ 0.2620631  -0.23374238  0.         -3.0848038   1.42453203 -1.73977595\n",
      " -1.33899673  1.58777895  0.53631739  0.45651289  0.67431732  0.31404177\n",
      "  0.93686807]\n",
      "[-0.28149464  0.07340172  0.          4.71754462 -1.58677255  2.21832487\n",
      "  1.83588149 -1.41898173  0.11215874  0.78418917  0.72647809  0.04382734\n",
      "  0.61141021]\n",
      "This is a critical connection\n",
      "This is a critical connection\n",
      "This is a critical connection\n",
      "[ 0.22591313 -0.21430375  0.         -1.84553928  1.46962915 -1.17070759\n",
      " -0.87953255  1.42336487  0.37089734 -0.32625016  0.0485132   0.59605682\n",
      "  0.55706958  0.5005393 ]\n",
      "[ 0.2620631  -0.23374238  0.         -3.0848038   1.42453203 -1.73977595\n",
      " -1.33899673  1.58777895  0.53631739  0.45651289  0.67431732  0.31404177\n",
      "  0.93686807  0.25708162]\n",
      "[-0.28149464  0.07340172  0.          4.71754462 -1.58677255  2.21832487\n",
      "  1.83588149 -1.41898173  0.11215874  0.78418917  0.72647809  0.04382734\n",
      "  0.61141021  0.93859041]\n",
      "This is a critical connection\n",
      "This is a critical connection\n",
      "This is a critical connection\n",
      "[ 0.22591313 -0.21430375  0.         -1.84553928  1.46962915 -1.17070759\n",
      " -0.87953255  1.42336487  0.37089734 -0.32625016  0.0485132   0.59605682\n",
      "  0.55706958  0.5005393   0.56080213]\n",
      "[ 0.2620631  -0.23374238  0.         -3.0848038   1.42453203 -1.73977595\n",
      " -1.33899673  1.58777895  0.53631739  0.45651289  0.67431732  0.31404177\n",
      "  0.93686807  0.25708162  0.99355119]\n",
      "[-0.28149464  0.07340172  0.          4.71754462 -1.58677255  2.21832487\n",
      "  1.83588149 -1.41898173  0.11215874  0.78418917  0.72647809  0.04382734\n",
      "  0.61141021  0.93859041  0.03698962]\n",
      "This is not a critical connection\n",
      "This is not a critical connection\n",
      "This is a critical connection\n",
      "Error: 0.40904181020018643 at epoch 1\n",
      "Error: 0.13206237434140813 at epoch 2\n",
      "Error: 0.015135332023646607 at epoch 3\n",
      "Error: 0.007615711385433561 at epoch 4\n",
      "Error: 0.005100564009101757 at epoch 5\n",
      "Error: 0.0038185372462153106 at epoch 6\n",
      "Error: 0.0030380770305544116 at epoch 7\n",
      "Error: 0.0025133501198771058 at epoch 8\n",
      "Error: 0.0021371048645211117 at epoch 9\n",
      "Error: 0.0018547168784978788 at epoch 10\n",
      "Error: 0.0016353626340179393 at epoch 11\n",
      "Error: 0.001460324680422532 at epoch 12\n",
      "Error: 0.001317587142508489 at epoch 13\n",
      "Error: 0.0011990902850275383 at epoch 14\n",
      "Error: 0.0010992315596924584 at epoch 15\n",
      "Error: 0.0010139991127469576 at epoch 16\n",
      "Error: 0.0009404470144287641 at epoch 17\n",
      "Error: 0.0008763648452433302 at epoch 18\n",
      "Error: 0.0008200626666962472 at epoch 19\n",
      "Error: 0.0007702270376600456 at epoch 20\n",
      "Error: 0.0007258221753000929 at epoch 21\n",
      "Error: 0.0006860206026105288 at epoch 22\n",
      "Error: 0.0006501535288753802 at epoch 23\n",
      "Error: 0.0006176747242459888 at epoch 24\n",
      "Error: 0.0005881338026124919 at epoch 25\n",
      "Error: 0.0005611561796981414 at epoch 26\n",
      "Error: 0.0005364278428971212 at epoch 27\n",
      "Error: 0.000513683640040468 at epoch 28\n",
      "Error: 0.000492698175863648 at epoch 29\n",
      "Error: 0.0004732786645194834 at epoch 30\n",
      "Error: 0.0004552592658467745 at epoch 31\n",
      "Error: 0.00043849655885711073 at epoch 32\n",
      "Error: 0.00042286589525331763 at epoch 33\n",
      "Error: 0.00040825844007171897 at epoch 34\n",
      "Error: 0.0003945787533186203 at epoch 35\n",
      "Error: 0.00038174280088139405 at epoch 36\n",
      "Error: 0.00036967630856210007 at epoch 37\n",
      "Error: 0.0003583133922583626 at epoch 38\n",
      "Error: 0.0003475954118271921 at epoch 39\n",
      "Error: 0.0003374700072393891 at epoch 40\n",
      "Error: 0.00032789028414640075 at epoch 41\n",
      "Error: 0.0003188141225774055 at epoch 42\n",
      "Error: 0.00031020358762996774 at epoch 43\n",
      "Error: 0.0003020244250583453 at epoch 44\n",
      "Error: 0.00029424562785663197 at epoch 45\n",
      "Error: 0.0002868390624722023 at epoch 46\n",
      "Error: 0.00027977914531414946 at epoch 47\n",
      "Error: 0.0002730425618524178 at epoch 48\n",
      "Error: 0.0002666080219210086 at epoch 49\n",
      "Error: 0.00026045604590840376 at epoch 50\n",
      "Training complete!\n",
      "=====\n",
      "[1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0]\n",
      "0.93\n",
      "[array([[-0.56272251,  0.14556564,  0.39138218],\n",
      "       [-5.08753835,  2.47674931,  4.88646242]]), array([[ 2.40599   ,  3.3670102 , -4.34982088],\n",
      "       [-1.89980552, -2.36886296,  2.61605599],\n",
      "       [-3.01414799, -4.36362055,  5.4877335 ]]), array([[ 0.13379099, -0.46327784, -0.24279504, -1.87100905,  1.57072636,\n",
      "        -1.30901592, -1.15262015,  1.50630533,  0.27193815, -0.6958853 ,\n",
      "        -0.46073315,  0.28019748,  0.83841207,  0.5315544 ,  0.51940643,\n",
      "         0.7715446 ],\n",
      "       [ 0.15250754, -0.51573143, -0.26837527, -3.1307399 ,  1.57013065,\n",
      "        -1.9193702 , -1.66658975,  1.71689677,  0.43261216,  0.04628637,\n",
      "         0.11176551, -0.03132994,  1.2672274 ,  0.29479349,  0.95749027,\n",
      "         0.36570614],\n",
      "       [-0.18046122,  0.32968199,  0.1282209 ,  4.87710697, -2.12682656,\n",
      "         2.60236823,  2.30244582, -2.01192666,  0.0696618 ,  1.00215423,\n",
      "         1.00423716,  0.18587412,  0.05130136,  0.84779043, -0.09476366,\n",
      "        -0.09362606]]), array([[-0.52697646, -0.0467169 ],\n",
      "       [ 0.36801183,  0.77104007],\n",
      "       [ 0.00469921,  0.47291047],\n",
      "       [ 2.00802639,  2.00324285],\n",
      "       [-1.97144574, -1.45613317],\n",
      "       [ 1.59229738,  1.74715049],\n",
      "       [ 1.89405172,  1.41938853],\n",
      "       [-1.55568336, -1.96183882],\n",
      "       [-0.30922311, -0.06287159],\n",
      "       [ 0.47674651,  0.58983533],\n",
      "       [ 0.54915334,  0.54315426],\n",
      "       [ 0.27129228, -0.09833402],\n",
      "       [-0.88029963, -1.13952145],\n",
      "       [-0.22431793, -0.04748292],\n",
      "       [-0.372262  , -0.54411203],\n",
      "       [-0.21217317, -0.78903477]])]\n"
     ]
    }
   ],
   "source": [
    "mlp = ANG(items, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30ccca76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.56272251,  0.14556564,  0.39138218],\n",
       "        [-5.08753835,  2.47674931,  4.88646242]]),\n",
       " array([[ 2.40599   ,  3.3670102 , -4.34982088],\n",
       "        [-1.89980552, -2.36886296,  2.61605599],\n",
       "        [-3.01414799, -4.36362055,  5.4877335 ]]),\n",
       " array([[ 0.13379099, -0.46327784, -0.24279504, -1.87100905,  1.57072636,\n",
       "         -1.30901592, -1.15262015,  1.50630533,  0.27193815, -0.6958853 ,\n",
       "         -0.46073315,  0.28019748,  0.83841207,  0.5315544 ,  0.51940643,\n",
       "          0.7715446 ],\n",
       "        [ 0.15250754, -0.51573143, -0.26837527, -3.1307399 ,  1.57013065,\n",
       "         -1.9193702 , -1.66658975,  1.71689677,  0.43261216,  0.04628637,\n",
       "          0.11176551, -0.03132994,  1.2672274 ,  0.29479349,  0.95749027,\n",
       "          0.36570614],\n",
       "        [-0.18046122,  0.32968199,  0.1282209 ,  4.87710697, -2.12682656,\n",
       "          2.60236823,  2.30244582, -2.01192666,  0.0696618 ,  1.00215423,\n",
       "          1.00423716,  0.18587412,  0.05130136,  0.84779043, -0.09476366,\n",
       "         -0.09362606]]),\n",
       " array([[-0.52697646, -0.0467169 ],\n",
       "        [ 0.36801183,  0.77104007],\n",
       "        [ 0.00469921,  0.47291047],\n",
       "        [ 2.00802639,  2.00324285],\n",
       "        [-1.97144574, -1.45613317],\n",
       "        [ 1.59229738,  1.74715049],\n",
       "        [ 1.89405172,  1.41938853],\n",
       "        [-1.55568336, -1.96183882],\n",
       "        [-0.30922311, -0.06287159],\n",
       "        [ 0.47674651,  0.58983533],\n",
       "        [ 0.54915334,  0.54315426],\n",
       "        [ 0.27129228, -0.09833402],\n",
       "        [-0.88029963, -1.13952145],\n",
       "        [-0.22431793, -0.04748292],\n",
       "        [-0.372262  , -0.54411203],\n",
       "        [-0.21217317, -0.78903477]])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2c986b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1.15461518, -1.64272619]),\n",
       " array([9.99877486e-01, 1.42493343e-02, 2.07739980e-04]),\n",
       " array([0.91513409, 0.96550832, 0.0132441 ]),\n",
       " array([0.56642845, 0.28545981, 0.38234413, 0.00928169, 0.94907972,\n",
       "        0.04668035, 0.06701864, 0.95300161, 0.66093712, 0.3591936 ,\n",
       "        0.42545436, 0.55690999, 0.87989725, 0.68617503, 0.80195152,\n",
       "        0.74229268]),\n",
       " array([0.01263833, 0.01221807])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966e2462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
